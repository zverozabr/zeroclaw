# Οδηγός Προσαρμοσμένων Παρόχων AI (Custom Providers)

Το ZeroClaw σας επιτρέπει να συνδεθείτε με δικές σας υπηρεσίες AI, όπως τοπικούς διακομιστές ή εταιρικά δίκτυα.

## Τύποι συνδέσεων

### 1. Σύνδεση τύπου OpenAI (`custom:`)

Για υπηρεσίες που λειτουργούν όπως το OpenAI:
```toml
default_provider = "custom:https://το-api-σας.com"
api_key = "το-κλειδί-σας"
default_model = "το-όνομα-του-μοντέλου"
```

### 2. Σύνδεση τύπου Anthropic (`anthropic-custom:`)

Για υπηρεσίες που λειτουργούν όπως το Anthropic:
```toml
default_provider = "anthropic-custom:https://το-api-σας.com"
api_key = "το-κλειδί-σας"
default_model = "το-όνομα-του-μοντέλου"
```

## Τοπική χρήση (στον υπολογιστή σας)

Αν τρέχετε το δικό σας μοντέλο AI τοπικά, μπορείτε να χρησιμοποιήσετε τα εξής:

- **llama.cpp**: Ρυθμίστε το `default_provider = "llamacpp"`.
- **vLLM**: Ρυθμίστε το `default_provider = "vllm"`.
- **SGLang**: Ρυθμίστε το `default_provider = "sglang"`.

Παράδειγμα για το **llama.cpp**:
```toml
default_provider = "llamacpp"
api_url = "http://127.0.0.1:8033/v1"
default_model = "το-μοντέλο-σας"
```

## Πώς να το δοκιμάσετε

Αφού αλλάξετε τις ρυθμίσεις, τρέξτε:
`zeroclaw agent -m "γεια σου"`
Αν η AI απαντήσει, η σύνδεση πέτυχε!

## Τι να κάνετε αν δεν δουλεύει

1. **Ελέγξτε το κλειδί (API Key)**: Βεβαιωθείτε ότι είναι σωστό.
2. **Ελέγξτε τη διεύθυνση (URL)**: Πρέπει να ξεκινάει με `http://` ή `https://`.
3. **Το μοντέλο δεν βρίσκεται**: Σιγουρευτείτε ότι το όνομα του μοντέλου είναι γραμμένο ακριβώς όπως το ορίζει ο πάροχος.

Μπορείτε να ελέγξετε αν η διεύθυνση λειτουργεί γράφοντας στο τερματικό:
`curl -I https://το-api-σας.com`
